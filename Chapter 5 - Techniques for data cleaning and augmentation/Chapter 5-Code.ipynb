{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ac6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_loan_prediction.csv')\n",
    "\n",
    "\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ea9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [cols for cols in df]\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_underscore_present_columns = [cols for cols in column_names if '_' not in cols]\n",
    "num_underscore_present_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b735f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_mappings = {}\n",
    "for cols in num_underscore_present_columns:\n",
    "    uppercase_in_cols = [val.isupper() for val in cols]\n",
    "    num_uppercase_letters = sum(uppercase_in_cols)\n",
    "\n",
    "    cols_mappings[cols] = {\n",
    "        \"is_uppercase_letter\": uppercase_in_cols,\n",
    "        \"num_uppercase_letters\": num_uppercase_letters,\n",
    "        \"needs_underscore\": (num_uppercase_letters > 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb08f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in cols_mappings.keys():\n",
    "    if cols_mappings[key]['needs_underscore']:\n",
    "        print()\n",
    "        print(f'{key} need the underscore at location ', cols_mappings[key]['is_uppercase_letter'].index(True, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'ApplicantIncome'[:9] + '_' + 'ApplicantIncome'[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06840af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_mappings = {}\n",
    "for cols in num_underscore_present_columns:\n",
    "    uppercase_in_cols = [val.isupper() for val in cols]\n",
    "    num_uppercase_letters = sum(uppercase_in_cols)\n",
    "    \n",
    "    if num_uppercase_letters > 1:\n",
    "        underscore_index = uppercase_in_cols.index(True, 1)\n",
    "        updated_column_name = cols[:underscore_index] + \"_\" + cols[underscore_index:]\n",
    "    else:\n",
    "        updated_column_name = cols\n",
    "\n",
    "    cols_mappings[cols] = {\n",
    "        \"is_uppercase_letter\": uppercase_in_cols,\n",
    "        \"num_uppercase_letters\": num_uppercase_letters,\n",
    "        \"needs_underscore\": (num_uppercase_letters > 1),\n",
    "        \"updated_column_name\": updated_column_name\n",
    "    }\n",
    "    if cols_mappings[cols]['needs_underscore']:\n",
    "        print(f\"{cols} will be renamed to {cols_mappings[cols]['updated_column_name']}\")\n",
    "        \n",
    "        \n",
    "column_mappings = {key: cols_mappings[key][\"updated_column_name\"] for key in cols_mappings.keys()}\n",
    "column_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea6b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=column_mappings)\n",
    "column_names = [cols for cols in df]\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ddbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([cols.lower() for cols in df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [cols.lower() for cols in df]\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'loan_id'\n",
    "target = 'loan_status'\n",
    "\n",
    "cat_cols = [cols for cols in df if df[cols].dtype == 'object' and cols not in [id_col, target]]\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b3ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in cat_cols:\n",
    "    print(cols)\n",
    "    print(df[cols].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab059f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent = df.copy()\n",
    "for col in cat_cols:\n",
    "\n",
    "    df_consistent[col] = df_consistent[col].apply(lambda val: val.lower() if isinstance(val, str) else val)\n",
    "\n",
    "    df_consistent[col] = df_consistent[col].apply(lambda val: val.replace(' ','_') if isinstance(val, str) else val)\n",
    "\n",
    "for cols in cat_cols:\n",
    "    print(cols)\n",
    "    print(df_consistent[cols].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent.dependents = df_consistent.dependents.apply(lambda val: float(val.replace('+','')) if isinstance(val, str) else float(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b041cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in ['married', 'self_employed']:\n",
    "    df_consistent[cols] = df_consistent[cols].map({\"yes\": 1, \"no\": 0})\n",
    "    \n",
    "df_consistent.education = df_consistent.education.map({\n",
    "    'graduate': 1,\n",
    "    'not_graduate': 0\n",
    "})\n",
    "\n",
    "\n",
    "df_consistent.gender = df_consistent.gender.map({\n",
    "    'male': 1,\n",
    "    'female': 0\n",
    "})\n",
    "\n",
    "for cols in cat_cols:\n",
    "    print(cols)\n",
    "    print(df_consistent[cols].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_consistent(df, cat_cols) -> pd.DataFrame:\n",
    "    \"\"\"Function to make data consistent and meaningful\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    for col in cat_cols:\n",
    "           \n",
    "        df[col] = df[col].apply(lambda val: val.lower() if isinstance(val, str) else val)\n",
    "        df[col] = df[col].apply(lambda val: val.replace(' ','_') if isinstance(val, str) else val)\n",
    "            \n",
    "    \n",
    "    df['dependents'] = df['dependents'].apply(lambda val: float(val.replace('+','')) if isinstance(val, str) else float(val))\n",
    "\n",
    "    for cols in ['married', 'self_employed']:\n",
    "        df[cols] = df[cols].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "    df['education'] = df['education'].map({\n",
    "        'graduate': 1,\n",
    "        'not_graduate': 0\n",
    "    })\n",
    "\n",
    "    df['gender'] = df['gender'].map({\n",
    "        'male': 1,\n",
    "        'female': 0\n",
    "    })\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent = df.copy()\n",
    "df_consistent = make_data_consistent(df=df_consistent, cat_cols=cat_cols)\n",
    "\n",
    "for cols in cat_cols:\n",
    "    print(cols)\n",
    "    print(df_consistent[cols].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90737e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loan_id.nunique(), df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224576a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['applicant_income', 'coapplicant_income', 'loan_amount']].value_counts().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.applicant_income == 4333) & (df.coapplicant_income == 2451) & (df.loan_amount == 110)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2957132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eeabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_rows = df_consistent.dropna(axis=0).shape[0]\n",
    "total_records = df_consistent.shape[0]\n",
    "perc_dropped = ((total_records - remaining_rows)/total_records)*100\n",
    "\n",
    "print(\"By dropping all missing data, only {:,} records will be left out of {:,}, a reduction by {:,.3f}%\".format(remaining_rows, total_records, perc_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'loan_id'\n",
    "target = 'loan_status'\n",
    "\n",
    "feature_cols = [cols for cols in df_consistent if cols not in [id_col, target]]\n",
    "binary_cols = [cols for cols in feature_cols if df_consistent[cols].nunique() == 2]\n",
    "cat_cols = [cols for cols in feature_cols if (df_consistent[cols].dtype == 'object' or df_consistent[cols].nunique() <= 15)]\n",
    "num_cols = [cols for cols in feature_cols if cols not in cat_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5697b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65aea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d4dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec8365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data_percentage(df: pd.DataFrame):\n",
    "    \"\"\"Function to print percentage of missing values\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    missing_data = df.isnull().sum()\n",
    "    total_records = df.shape[0]\n",
    "    \n",
    "    perc_missing = round((missing_data/total_records)*100, 3)\n",
    "    \n",
    "    missing_df = pd.DataFrame(data={'columm_name':perc_missing.index, 'perc_missing':perc_missing.values})\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "\n",
    "missing_data_percentage(df_consistent[feature_cols]).sort_values(by='perc_missing', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_consistent[feature_cols], figsize=(35, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244f3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(df_consistent[feature_cols], labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = [cols for cols in feature_cols if df_consistent[cols].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(df_consistent[missing_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_missing = [cols for cols in cat_cols if df_consistent[cols].isnull().sum() > 0]\n",
    "\n",
    "def cat_missing_association_with_outcome(data, missing_data_column, outcome):\n",
    "    \"\"\"Function to plot missing association of categorical varibles with outcome\"\"\"\n",
    "    \n",
    "    df = data.copy()\n",
    "    df[f\"{missing_data_column}_is_missing\"] = df[missing_data_column].isnull().astype(int)\n",
    "    df.groupby([outcome]).agg({f\"{missing_data_column}_is_missing\": 'mean'}).plot.bar()\n",
    "    \n",
    "for cols in cat_missing:\n",
    "    cat_missing_association_with_outcome(df_consistent, cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade7d10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_missing = [cols for cols in num_cols if df_consistent[cols].isnull().sum() > 0]\n",
    "\n",
    "def num_missing_association_with_outcome(data, missing_data_column, outcome):\n",
    "    \"\"\"Function to plot missing association of categorical varibles with outcome\"\"\"\n",
    "    \n",
    "    df = data.copy()\n",
    "    df[f\"{missing_data_column}_is_missing\"] = df[missing_data_column].isnull().astype(int)\n",
    "    df.groupby([outcome]).agg({f\"{missing_data_column}_is_missing\": 'mean'}).plot.bar()\n",
    "\n",
    "\n",
    "for cols in num_missing:\n",
    "    num_missing_association_with_outcome(df, cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent.loan_amount.plot.kde(color='orange', label='loan_amount', legend=True)\n",
    "df_consistent.loan_amount.fillna(value=df.loan_amount.median()).plot.kde(color='b', label='loan_amount_imputed', alpha=0.5, figsize=(9,7), legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42602619",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_consistent.loan_amount.std(),2), round(df_consistent.loan_amount.fillna(value=df_consistent.loan_amount.median()).std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent[num_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97281f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = df_consistent[df_consistent.loan_amount.isnull()]\n",
    "imputed_values = []\n",
    "for idx in observation.index:\n",
    "    seed = int(observation.loc[idx,['applicant_income']])\n",
    "    imputed_value = df_consistent['loan_amount'].dropna().sample(1, random_state=seed)\n",
    "    imputed_values.append(imputed_value)\n",
    "\n",
    "df_consistent.loc[df_consistent['loan_amount'].isnull(),'loan_amount_random_imputed']=imputed_values \n",
    "df_consistent.loc[df['loan_amount'].isnull()==False,'loan_amount_random_imputed']=df_consistent[df_consistent['loan_amount'].isnull()==False]['loan_amount'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43575e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent.loan_amount.plot.kde(color='orange', label='loan_amount', legend=True, linewidth=2)\n",
    "df_consistent.loan_amount_random_imputed.plot.kde(color='g', label='loan_amount_random_imputed', legend=True, linewidth=2)\n",
    "df_consistent.loan_amount.fillna(value=df_consistent.loan_amount.median()).plot.kde(color='b', label='loan_amount_median_imputed', linewidth=1, alpha=0.5, figsize=(9,7), legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e79d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_consistent.loan_amount.std(),2), round(df_consistent.loan_amount_random_imputed.std(),2), round(df_consistent.loan_amount.fillna(value=df_consistent.loan_amount.median()).std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7367e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent['loan_amount_median_imputed'] = df_consistent['loan_amount'].fillna(value=df_consistent['loan_amount'].median())\n",
    "df_consistent[['loan_amount', 'loan_amount_median_imputed','loan_amount_random_imputed', 'applicant_income']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent.credit_history.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef575383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent.credit_history.fillna(value=df_consistent.credit_history.mode()[0]).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2317a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [cols for cols in df_consistent if df_consistent[cols].nunique() > 15 and cols not in [id_col, target] and not cols.endswith('imputed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ec4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_consistent[num_cols].copy()\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566194a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df, scaler, columns):\n",
    "    \"\"\"Function to scale the data\"\"\"\n",
    "    \n",
    "    df_scaled = df.copy()\n",
    "    if columns:\n",
    "        df_scaled[columns] = scaler.fit_transform(df_scaled[columns])\n",
    "    else:\n",
    "        columns = [cols for cols in df_scaled]\n",
    "        df_scaled[columns] = scaler.fit_transform(df_scaled[columns])\n",
    "    \n",
    "    return df_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled, scaler = scale_data(df_num, scaler=scaler, columns=num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = SklearnTransformerWrapper(\n",
    "    transformer = KNNImputer(n_neighbors=10, weights='distance'),\n",
    "    variables = num_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29304a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = knn_imputer.fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afebb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = pd.DataFrame(columns=num_cols, data=scaler.inverse_transform(df_imputed))\n",
    "df_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f76307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed['loan_amount'].plot.kde(color='orange', label='loan_amount_knn_imputed',linewidth=2, legend=True)\n",
    "df_consistent['loan_amount'].plot.kde(color='b', label='loan_amount', legend=True, linewidth=2, figsize=(9,7), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_consistent.loan_amount.std(),2), round(df_consistent.loan_amount_random_imputed.std(),2), round(df_consistent.loan_amount_median_imputed.std(),2), round(df_imputed.loan_amount.std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf535d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent['loan_amount_knn_imputed'] = df_imputed.loan_amount\n",
    "df_consistent[['loan_amount', 'loan_amount_median_imputed','loan_amount_random_imputed', 'loan_amount_knn_imputed', 'applicant_income']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4938a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from feature_engine.encoding import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633424cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = [cols for cols in cat_cols if df_consistent[cols].dtype == 'object']\n",
    "ohe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7545043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe_encoded = df_consistent.copy()\n",
    "ohe = OneHotEncoder(variables=ohe_cols)\n",
    "df_ohe_encoded = ohe.fit_transform(df_ohe_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f7af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ohe_encoded[[cols for cols in df_ohe_encoded if 'property_area' in cols]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd17b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [cols for cols in df_ohe_encoded if df_ohe_encoded[cols].nunique() <= 15 and cols not in [id_col, target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50899fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5894e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_forest_classifier = IterativeImputer(estimator=ExtraTreesClassifier(n_estimators=100, \n",
    "                                                                        random_state=1,\n",
    "                                                                        bootstrap=True, \n",
    "                                                                        n_jobs=-1),\n",
    "                           max_iter=10,\n",
    "                           random_state=1,\n",
    "                           add_indicator=True,\n",
    "                           initial_strategy='median')\n",
    "\n",
    "df_cat_imputed = miss_forest_classifier.fit_transform(df_ohe_encoded[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_imputed = pd.DataFrame(columns=miss_forest_classifier.get_feature_names_out(), \n",
    "                               data=df_cat_imputed, \n",
    "                               index=df_ohe_encoded.index)\n",
    "df_cat_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in cat_cols:\n",
    "    print(cols)\n",
    "    print(df_cat_imputed[cols].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [cols for cols in df_consistent if cols not in df_cat_imputed and cols not in [id_col, target] + ohe_cols \n",
    "            and not cols.endswith(\"imputed\")]\n",
    "\n",
    "df_combined = pd.concat([df_consistent[num_cols], df_cat_imputed], axis=1)\n",
    "feature_cols = [cols for cols in df_combined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fc14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e413902",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_forest_regressor = IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=100, \n",
    "                                                                       random_state=1, \n",
    "                                                                       bootstrap=True, \n",
    "                                                                       n_jobs=-1),\n",
    "                           max_iter=10,\n",
    "                           random_state=1,\n",
    "                           add_indicator=True,\n",
    "                           initial_strategy='median')\n",
    "\n",
    "df_imputed = miss_forest_regressor.fit_transform(df_combined[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = pd.DataFrame(data=df_imputed, \n",
    "                           columns=miss_forest_regressor.get_feature_names_out(),\n",
    "                           index=df_combined.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31586252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed['loan_amount'].plot.kde(color='orange', label='loan_amount_miss_forest_imputed',linewidth=2, legend=True)\n",
    "df_consistent['loan_amount'].plot.kde(color='b', label='loan_amount', legend=True, linewidth=2, figsize=(9,7), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_consistent.loan_amount.std(),2), round(df_consistent.loan_amount_random_imputed.std(),2), round(df_consistent.loan_amount_median_imputed.std(),2), round(df_imputed.loan_amount.std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15dd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_consistent['loan_amount_miss_forest_imputed'] = df_imputed.loan_amount\n",
    "df_consistent[['loan_amount', 'loan_amount_median_imputed','loan_amount_random_imputed', 'loan_amount_miss_forest_imputed', 'applicant_income']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb94e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistent.drop([cols for cols in df_consistent if cols.endswith('imputed')], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from typing import List\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2fb82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [cols for cols in df_consistent if cols not in [target, id_col]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_consistent[feature_cols],\n",
    "                                                    df_consistent[target].map({'Y':1, 'N':0}), \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=df_consistent[target].map({'Y':1, 'N':0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [cols for cols in X_train if X_train[cols].nunique() <= 15]\n",
    "num_cols = [cols for cols in X_train if cols not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77259a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss_forest_categorical_transformer():\n",
    "    \"\"\"Function to define categorical pipeline\"\"\"\n",
    "    \n",
    "    cat_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"one_hot_encoding\", \n",
    "             OneHotEncoder(variables=ohe_cols)\n",
    "            ),\n",
    "\n",
    "            (\"miss_forest_classifier\",\n",
    "             IterativeImputer(\n",
    "                estimator=ExtraTreesClassifier(n_estimators=100,\n",
    "                                              random_state=1,\n",
    "                                              bootstrap=True, \n",
    "                                              n_jobs=-1),\n",
    "                max_iter=10,\n",
    "                random_state=1,\n",
    "                initial_strategy='median',\n",
    "                add_indicator=True)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return cat_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss_forest_numerical_transformer():\n",
    "    \"\"\"Function to define numerical pipeline\"\"\"\n",
    "    \n",
    "    num_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"miss_forest\", \n",
    "             IterativeImputer(\n",
    "                estimator=ExtraTreesRegressor(n_estimators=100,\n",
    "                                              random_state=1,\n",
    "                                              bootstrap=True, \n",
    "                                              n_jobs=-1),\n",
    "                max_iter=10,\n",
    "                random_state=1,\n",
    "                initial_strategy='median',\n",
    "                add_indicator=True)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return num_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47641bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = miss_forest_categorical_transformer()\n",
    "num_transformer = miss_forest_numerical_transformer()\n",
    "\n",
    "\n",
    "X_train_cat_imputed = cat_transformer.fit_transform(X_train[cat_cols])\n",
    "X_test_cat_imputed = cat_transformer.transform(X_test[cat_cols])\n",
    "\n",
    "X_train_cat_imputed_df = pd.DataFrame(data=X_train_cat_imputed, \n",
    "                                      columns=cat_transformer.get_feature_names_out(),\n",
    "                                      index=X_train.index) \n",
    "\n",
    "X_test_cat_imputed_df = pd.DataFrame(data=X_test_cat_imputed, \n",
    "                                     columns=cat_transformer.get_feature_names_out(),\n",
    "                                     index=X_test.index)\n",
    "\n",
    "X_train_cat_imputed_df = pd.concat([X_train_cat_imputed_df, X_train[num_cols]], axis=1)\n",
    "X_test_cat_imputed_df = pd.concat([X_test_cat_imputed_df, X_test[num_cols]], axis=1)\n",
    "\n",
    "\n",
    "X_train_imputed = num_transformer.fit_transform(X_train_cat_imputed_df)\n",
    "X_test_imputed = num_transformer.transform(X_test_cat_imputed_df)\n",
    "\n",
    "X_train_transformed = pd.DataFrame(data=X_train_imputed, \n",
    "                                   columns=num_transformer.get_feature_names_out(),\n",
    "                                   index=X_train.index)\n",
    "\n",
    "X_test_transformed = pd.DataFrame(data=X_test_imputed, \n",
    "                                  columns=num_transformer.get_feature_names_out(),\n",
    "                                  index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ac38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_param_grid = {\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8,10,20],\n",
    "    'min_samples_leaf' : [1,3,5,8,10,12,15],\n",
    "    'min_samples_split': [2,6,10,16,20,24,30],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'random_state' : [1], \n",
    "    'class_weight' : ['balanced']\n",
    "}\n",
    "d_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f38b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_custom_classifier(X_train, y_train, X_test, y_test, clf, params):\n",
    "    \"\"\"Function to train the decision tree classifier and return some metrics\"\"\"\n",
    "\n",
    "    d_clf_cv = GridSearchCV(estimator=d_clf, param_grid=d_param_grid, cv=10, scoring='roc_auc')\n",
    "    d_clf_cv.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Decision tree optimised\")\n",
    "\n",
    "\n",
    "    d_best_params = d_clf_cv.best_params_\n",
    "\n",
    "    print(f\"Getting the best params which are {d_best_params}\")\n",
    "\n",
    "    model = DecisionTreeClassifier(**d_best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    training_predictions_prob = model.predict_proba(X_train)\n",
    "    testing_predictions_prob = model.predict_proba(X_test)\n",
    "\n",
    "    training_predictions = model.predict(X_train)\n",
    "    testing_predictions = model.predict(X_test)\n",
    "\n",
    "    training_roc_auc = roc_auc_score(y_train, training_predictions_prob[:,1])\n",
    "    testing_roc_auc = roc_auc_score(y_test, testing_predictions_prob[:,1])\n",
    "\n",
    "    training_acc = accuracy_score(y_train, training_predictions)\n",
    "    testing_acc = accuracy_score(y_test, testing_predictions)\n",
    "\n",
    "    print(f\"Training roc is {training_roc_auc}, and testing roc is {testing_roc_auc} \\n \\\n",
    "            training accuracy is {training_acc}, testing_acc as {testing_acc}\")\n",
    "    \n",
    "    return model, testing_predictions, training_roc_auc, testing_roc_auc, training_acc, testing_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2802521",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, test_predictions, train_roc, test_roc, train_acc, test_acc  = train_custom_classifier(\n",
    "    X_train=X_train_transformed, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test_transformed, \n",
    "    y_test=y_test, \n",
    "    clf=d_clf, \n",
    "    params=d_param_grid\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ed986",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, test_predictions, labels=model.classes_, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e1edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"one_hot_encoding\", \n",
    "         OneHotEncoder(variables=ohe_cols)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "impute_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"simple_imputer\", \n",
    "         SimpleImputer(strategy='median',\n",
    "                       add_indicator=True)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_ohe = cat_transformer.fit_transform(X_train)\n",
    "X_test_ohe = cat_transformer.transform(X_test)\n",
    "\n",
    "\n",
    "X_train_imputed = impute_transformer.fit_transform(X_train_ohe)\n",
    "X_test_imputed = impute_transformer.transform(X_test_ohe)\n",
    "\n",
    "\n",
    "X_train_transformed = pd.DataFrame(data=X_train_imputed, \n",
    "                                   columns=impute_transformer.get_feature_names_out(),\n",
    "                                   index=X_train.index)\n",
    "\n",
    "X_test_transformed = pd.DataFrame(data=X_test_imputed, \n",
    "                                  columns=impute_transformer.get_feature_names_out(),\n",
    "                                  index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, test_predictions, train_roc, test_roc, train_acc, test_acc = train_custom_classifier(\n",
    "    X_train=X_train_transformed, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test_transformed, \n",
    "    y_test=y_test, \n",
    "    clf=d_clf, \n",
    "    params=d_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f107e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, test_predictions, labels=model.classes_, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4953b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cutoff_points = np.linspace(start=0.1, stop=1, num=10)\n",
    "data_cutoff_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for cutoff in data_cutoff_points:\n",
    "    if cutoff < 1.0:\n",
    "        X_train_subset, X_train_rem, y_train_subset, y_train_rem = train_test_split(X_train, \n",
    "                                                                                y_train, \n",
    "                                                                                random_state=1, \n",
    "                                                                                train_size=cutoff, \n",
    "                                                                                stratify=y_train)\n",
    "    else:\n",
    "        X_train_subset = X_train.copy()\n",
    "        y_train_subset = y_train.copy()\n",
    "    \n",
    "    print(f\"Model will be trained on {X_train_subset.shape[0]} rows out of {X_train.shape[0]}\")\n",
    "    \n",
    "\n",
    "    cat_transformer = miss_forest_categorical_transformer()\n",
    "    num_transformer = miss_forest_numerical_transformer()\n",
    "    \n",
    "    X_train_cat_imputed = cat_transformer.fit_transform(X_train_subset[cat_cols])\n",
    "    X_test_cat_imputed = cat_transformer.transform(X_test[cat_cols])\n",
    "\n",
    "    X_train_cat_imputed_df = pd.DataFrame(data=X_train_cat_imputed, \n",
    "                                          columns=cat_transformer.get_feature_names_out(),\n",
    "                                          index=X_train_subset.index)\n",
    "\n",
    "    X_test_cat_imputed_df = pd.DataFrame(data=X_test_cat_imputed, \n",
    "                                         columns=cat_transformer.get_feature_names_out(),\n",
    "                                         index=X_test.index)\n",
    "\n",
    "    X_train_cat_imputed_df = pd.concat([X_train_cat_imputed_df, X_train_subset[num_cols]], axis=1)\n",
    "    X_test_cat_imputed_df = pd.concat([X_test_cat_imputed_df, X_test[num_cols]], axis=1)\n",
    "\n",
    "    X_train_imputed = num_transformer.fit_transform(X_train_cat_imputed_df)\n",
    "    X_test_imputed = num_transformer.transform(X_test_cat_imputed_df)\n",
    "\n",
    "    X_train_transformed = pd.DataFrame(data=X_train_imputed, \n",
    "                                       columns=num_transformer.get_feature_names_out(),\n",
    "                                       index=X_train_subset.index)\n",
    "\n",
    "    X_test_transformed = pd.DataFrame(data=X_test_imputed, \n",
    "                                      columns=num_transformer.get_feature_names_out(),\n",
    "                                      index=X_test.index)\n",
    "    \n",
    "    model, test_predictions, train_roc, test_roc, train_acc, test_acc = train_custom_classifier(\n",
    "        X_train=X_train_transformed, \n",
    "        y_train=y_train_subset, \n",
    "        X_test=X_test_transformed, \n",
    "        y_test=y_test, \n",
    "        clf=d_clf, \n",
    "        params=d_param_grid)\n",
    "    \n",
    "    scores.append((cutoff, train_roc, test_roc, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d3e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=scores, columns=['data_size', 'training_roc', 'testing_roc', \"training_acc\", \"testing_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.data_size, df.training_roc, label='training_roc')\n",
    "plt.plot(df.data_size, df.testing_roc, label='testing_roc')\n",
    "plt.xlabel(\"Data Size\")\n",
    "plt.ylabel(\"ROC\")\n",
    "plt.title(\"Error Analysis\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.data_size, df.training_acc, label='training_acc')\n",
    "plt.plot(df.data_size, df.testing_acc, label='testing_acc')\n",
    "plt.xlabel(\"Data Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Error Analysis\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_variables = ['applicant_income', 'coapplicant_income']\n",
    "loan_variable = ['loan_amount']\n",
    "loan_term_variable = ['loan_amount_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.creation.math_features import MathFeatures\n",
    "from feature_engine.creation.relative_features import RelativeFeatures\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from feature_engine.selection import DropFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom pipeline class to multiply columns passed in a dataframe with a value\"\"\"\n",
    "    \n",
    "    def __init__(self, multiply_by=1, variables=None):\n",
    "        self.multiply_by = multiply_by\n",
    "        self.variables = variables\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.variables:\n",
    "            X[self.variables] = X[self.variables] * self.multiply_by\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = miss_forest_categorical_transformer()\n",
    "num_transformer = miss_forest_numerical_transformer()\n",
    "        \n",
    "\n",
    "feature_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"multiply_by_thousand\",\n",
    "         MultiplyColumns(\n",
    "             multiply_by=1000,\n",
    "             variables=loan_variable\n",
    "         )\n",
    "        ),\n",
    "        (\"add_columns\",\n",
    "         MathFeatures(\n",
    "             variables=income_variables,\n",
    "             func='sum'\n",
    "         )   \n",
    "        ),\n",
    "        (\"income_to_loan_ratio\",\n",
    "         RelativeFeatures(variables=[f\"sum_{income_variables[0]}_{income_variables[1]}\"],\n",
    "                          reference=loan_variable,\n",
    "                          func=[\"div\"]\n",
    "                         )\n",
    "        ),\n",
    "        (\"emi\",\n",
    "         RelativeFeatures(variables=loan_variable,\n",
    "                          reference=loan_term_variable,\n",
    "                          func=[\"div\"])\n",
    "        ),\n",
    "        (\"drop_features\",\n",
    "         DropFeatures(features_to_drop=income_variables\n",
    "          ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "X_train_cat_imputed = cat_transformer.fit_transform(X_train[cat_cols])\n",
    "X_test_cat_imputed = cat_transformer.transform(X_test[cat_cols])\n",
    "\n",
    "X_train_cat_imputed_df = pd.DataFrame(data=X_train_cat_imputed, \n",
    "                                      columns=cat_transformer.get_feature_names_out(),\n",
    "                                      index=X_train.index) \n",
    "\n",
    "X_test_cat_imputed_df = pd.DataFrame(data=X_test_cat_imputed, \n",
    "                                     columns=cat_transformer.get_feature_names_out(),\n",
    "                                     index=X_test.index)\n",
    "\n",
    "X_train_cat_imputed_df = pd.concat([X_train_cat_imputed_df, X_train[num_cols]], axis=1)\n",
    "X_test_cat_imputed_df = pd.concat([X_test_cat_imputed_df, X_test[num_cols]], axis=1)\n",
    "\n",
    "\n",
    "X_train_imputed = num_transformer.fit_transform(X_train_cat_imputed_df)\n",
    "X_test_imputed = num_transformer.transform(X_test_cat_imputed_df)\n",
    "\n",
    "X_train_imputed_df = pd.DataFrame(data=X_train_imputed, \n",
    "                                   columns=num_transformer.get_feature_names_out(),\n",
    "                                   index=X_train.index)\n",
    "\n",
    "X_test_imputed_df = pd.DataFrame(data=X_test_imputed, \n",
    "                                  columns=num_transformer.get_feature_names_out(),\n",
    "                                  index=X_test.index)\n",
    "\n",
    "\n",
    "X_train_transformed = feature_transformer.fit_transform(X_train_imputed_df)\n",
    "X_test_transformed = feature_transformer.transform(X_test_imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, test_predictions, train_roc, test_roc, train_acc, test_acc = train_custom_classifier(\n",
    "    X_train=X_train_transformed, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test_transformed, \n",
    "    y_test=y_test, \n",
    "    clf=d_clf, \n",
    "    params=d_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d962f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, test_predictions, labels=model.classes_, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from collections import Counter\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82333c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "over_sampling = [0.65,0.7, 0.75, 0.8, 'auto']\n",
    "n_neighbours = [1,3,5,7,9,10]\n",
    "for os in over_sampling:\n",
    "    for k in n_neighbours:\n",
    "        oversample = ADASYN(random_state=1, sampling_strategy=os, n_neighbors=k)\n",
    "        counter = Counter(y_train)\n",
    "        print(f\"data size before applying smote technique is {counter}\")\n",
    "        X_train_synthetic, y_train_synthetic = oversample.fit_resample(X_train_transformed, y_train)\n",
    "        \n",
    "        counter = Counter(y_train_synthetic)\n",
    "        print(f\"data size after applying smote technique is {counter}\")\n",
    "        \n",
    "        model, test_predictions, train_roc, test_roc, train_acc, test_acc = train_custom_classifier(\n",
    "        X_train=X_train_synthetic, \n",
    "        y_train=y_train_synthetic, \n",
    "        X_test=X_test_transformed, \n",
    "        y_test=y_test, \n",
    "        clf=d_clf, \n",
    "        params=d_param_grid)\n",
    "\n",
    "        results.append((os, k, train_roc, test_roc, train_acc, test_acc))\n",
    "        \n",
    "synthetic_df = pd.DataFrame(columns=['os_strategy', \"n_neighbours\", \"train_roc\", \"test_roc\", \"train_acc\", \"test_acc\"], data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1277f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "synthetic_df.sort_values(by=\"test_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5831fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train)\n",
    "print(f\"data size before applying smote technique {tech_name} is {counter}\")\n",
    "# transform the dataset\n",
    "oversample = ADASYN(random_state=1, n_neighbors=7, sampling_strategy=0.75)\n",
    "X_train_synthetic, y_train_synthetic = oversample.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "counter = Counter(y_train_synthetic)\n",
    "print(f\"data size after applying smote technique {tech_name} is {counter}\")\n",
    "\n",
    "model, test_predictions, train_roc, test_roc, train_acc, test_acc = train_custom_classifier(\n",
    "X_train=X_train_synthetic, \n",
    "y_train=y_train_synthetic, \n",
    "X_test=X_test_transformed, \n",
    "y_test=y_test, \n",
    "clf=d_clf, \n",
    "params=d_param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "data = {\n",
    "    \"id\": np.linspace(start=1, stop=10, num=10, dtype=int),\n",
    "    \"population\" : np.random.randint(low=1000, high=100000, size=10),\n",
    "    \"property_area\": [\"urban\"]*4 + [\"semi_urban\"]*5 + [\"rural\"]*1\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245aaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.property_area.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ddd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.property_area.isin(['rural', 'urban']) == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.property_area.isin(['rural', 'urban']) == False) / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adda1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['true_property_area'] = df.population.apply(lambda value: 'rural' if value <= 20000 else 'urban')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['true_property_area', 'property_area', 'population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0212a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.property_area == df.true_property_area) / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ad7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred=df.property_area, y_true=df.true_property_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e72cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "numdays = 100\n",
    "base = datetime.today() \n",
    "date_list = [base - timedelta(days=day) for day in range(numdays)] # Subracting values from 1 to 100 from todays date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9943ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[date.date().strftime('%Y-%m-%d') for date in date_list[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821553e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) \n",
    "data = {\n",
    "    \"id\": np.linspace(start=1, stop=100, num=100, dtype=int),\n",
    "    \"population\" : np.random.randint(low=1000, high=100000, size=100),\n",
    "    \"property_area\": [\"urban\"]*40 + [\"semi_urban\"]*50 + [\"rural\"]*10,\n",
    "    \"date_loaded\": date_list\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc91c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(datetime.now() - df.date_loaded.max()).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_recency_days(df: pd.DataFrame, loaded_at_column: str, warning_at: int=5, error_at: int=10):\n",
    "    \"\"\"Function to detect data freshness\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    days_since_data_refreshed = (datetime.now() - df[loaded_at_column].max()).days\n",
    "    \n",
    "    if days_since_data_refreshed < warning_at:\n",
    "        print(f\"Data is fresh and is {days_since_data_refreshed} days old\")\n",
    "    \n",
    "    elif error_at > days_since_data_refreshed >= warning_at:\n",
    "        warnings.warn(f\"Warning: Data is not fresh, and is {days_since_data_refreshed} days old\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Date provided is too old and stale, please contact source provider: {days_since_data_refreshed} days old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_recency_days(df, \"date_loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_6_days = df[df.date_loaded <= (datetime.today() -  timedelta(days=6))] \n",
    "df_filter_12_days = df[df.date_loaded <= (datetime.today() -  timedelta(days=12))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_recency_days(df_filter_6_days, \"date_loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import alibi\n",
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = TabularDrift(x_ref=X_train_transformed.to_numpy(), p_val=.05 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0de37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cd.predict(X_test_transformed.to_numpy())\n",
    "labels = ['No', 'Yes']\n",
    "print('Drift: {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e557fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed['loan_amount'] = X_test_transformed['loan_amount']*1.5\n",
    "X_test_transformed['sum_applicant_income_coapplicant_income'] = X_test_transformed['sum_applicant_income_coapplicant_income']*1.2\n",
    "X_test_transformed.sum_applicant_income_coapplicant_income_div_loan_amount = X_test_transformed.sum_applicant_income_coapplicant_income/X_test_transformed.loan_amount\n",
    "X_test_transformed.loan_amount_div_loan_amount_term = X_test_transformed.loan_amount/X_test_transformed.loan_amount_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6940c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cd.predict(X_test_transformed.to_numpy())\n",
    "labels = ['No', 'Yes']\n",
    "print('Drift: {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predictions_prob = model.predict_proba(X_test_transformed)\n",
    "testing_predictions = model.predict(X_test_transformed)\n",
    "\n",
    "testing_roc_auc = roc_auc_score(y_test, testing_predictions_prob[:,1])\n",
    "testing_acc = accuracy_score(y_test, testing_predictions)\n",
    "\n",
    "print(f\"Testing roc is {testing_roc_auc} and testing_acc as {testing_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
